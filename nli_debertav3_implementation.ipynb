{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0a56d2-0cab-456a-a292-325f044f76a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "import transformers\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import DebertaV2Tokenizer\n",
    "from transformers import DebertaV2Model\n",
    "import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.nn import functional as F\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e89a8e-0c9f-4383-a89d-3a45c424807f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the device for GPU usage\n",
    "from torch import cuda\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e92aeba-5b59-4e2a-bd0f-c6e31350807a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/storage/home/ndh5286/Projects/MOTN Transformer/final_model_6.2.24.csv\", encoding = 'latin-1')\n",
    "df = pd.DataFrame(df)\n",
    "df = df.iloc[: , 1:]\n",
    "\n",
    "np.random.seed(1337)\n",
    "\n",
    "# Creates the dataframe\n",
    "df['list'] = df[df.columns[2:]].values.tolist()\n",
    "new_df = df[['CASEID', 'comment_text', 'list']].copy()\n",
    "\n",
    "# Applies float to list\n",
    "new_df['list'] = new_df['list'].apply(lambda x: [float(i) for i in x])\n",
    "new_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c853982-6a87-4343-8392-181d890bf095",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining some key variables that will be used later on in the training\n",
    "MAX_LEN = 200\n",
    "TRAIN_BATCH_SIZE = 8 #8\n",
    "VALID_BATCH_SIZE = 4 #4\n",
    "EPOCHS = 15\n",
    "LEARNING_RATE = 1e-05\n",
    "\n",
    "# Defining Tokenizer\n",
    "tokenizer = DebertaV2Tokenizer.from_pretrained(\"MoritzLaurer/DeBERTa-v3-base-mnli-fever-anli\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69595131-ddb0-4971-a28b-5353fb27ff1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining CustomDataset class\n",
    "class CustomDataset(Dataset): # Inherits Dataset class from PyTorch\n",
    "\n",
    "    def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = dataframe\n",
    "        self.comment_text = dataframe.comment_text\n",
    "        self.targets = self.data.list\n",
    "        self.CASEID = self.data.CASEID\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.comment_text)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        comment_text = str(self.comment_text[index])\n",
    "        comment_text = \" \".join(comment_text.split())\n",
    "\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            comment_text,\n",
    "            None,\n",
    "            add_special_tokens = True,\n",
    "            max_length = self.max_len,\n",
    "            pad_to_max_length = True,\n",
    "            return_token_type_ids = True\n",
    "        )\n",
    "        ids = inputs['input_ids']\n",
    "        mask = inputs['attention_mask']\n",
    "        token_type_ids = inputs[\"token_type_ids\"]\n",
    "\n",
    "\n",
    "        return {\n",
    "            'caseid': self.CASEID[index],\n",
    "            'text': comment_text,\n",
    "            'ids': torch.tensor(ids, dtype = torch.long),\n",
    "            'mask': torch.tensor(mask, dtype=torch.long),\n",
    "            'token_type_ids': torch.tensor(token_type_ids, dtype = torch.long),\n",
    "            'targets': torch.tensor(self.targets[index], dtype = torch.float)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b13c5f5-276d-4e3a-b690-6639892c834e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the dataset and dataloader for the neural network\n",
    "\n",
    "# Split the dataset into train and test\n",
    "train_size = 0.8\n",
    "train_dataset = new_df.sample(frac = train_size, random_state = 200)\n",
    "test_dataset = new_df.drop(train_dataset.index).reset_index(drop = True)\n",
    "train_dataset = train_dataset.reset_index(drop = True)\n",
    "\n",
    "# Split the train_dataset further into train and validation\n",
    "train_split = 0.8\n",
    "train_indices, val_indices = train_test_split(train_dataset.index, test_size = 1-train_split, random_state = 200)\n",
    "train_split_dataset = train_dataset.loc[train_indices].reset_index(drop = True)\n",
    "val_dataset = train_dataset.loc[val_indices].reset_index(drop = True)\n",
    "\n",
    "print(\"FULL Dataset: {}\".format(new_df.shape))\n",
    "print(\"TRAIN Dataset: {}\".format(train_split_dataset.shape))\n",
    "print(\"TEST Dataset: {}\".format(test_dataset.shape))\n",
    "print(\"VALIDATION Dataset: {}\".format(val_dataset.shape))\n",
    "\n",
    "# Create the datasets\n",
    "training_set = CustomDataset(train_split_dataset, tokenizer, MAX_LEN)\n",
    "testing_set = CustomDataset(test_dataset, tokenizer, MAX_LEN)\n",
    "validation_set = CustomDataset(val_dataset, tokenizer, MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15af4425-5697-4995-90a6-98f35ee0ac98",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "training_loader = DataLoader(training_set, **train_params)\n",
    "testing_loader = DataLoader(testing_set, **test_params)\n",
    "validation_loader = DataLoader(validation_set, **test_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ac7d09-4fb1-411d-9433-1484b4c87289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the customized model by adding dropout.\n",
    "\n",
    "# class BERTClass(torch.nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(BERTClass, self).__init__()\n",
    "#         self.l1 = transformers.RobertaModel.from_pretrained('roberta-base')\n",
    "#         self.l2 = torch.nn.Dropout(0.2)\n",
    "#         self.l3 = torch.nn.Linear(768, 13)  # Num of labels is 13\n",
    "    \n",
    "#     def forward(self, ids, mask, token_type_ids):\n",
    "#         _, output_1 = self.l1(ids, attention_mask=mask, token_type_ids=token_type_ids, return_dict=False)\n",
    "#         output_2 = self.l2(output_1)\n",
    "#         output = self.l3(output_2)\n",
    "#         return output\n",
    "\n",
    "class DEBERTAClass(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.l1 = DebertaV2Model.from_pretrained(\"MoritzLaurer/DeBERTa-v3-base-mnli-fever-anli\")\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.layer_norm = nn.LayerNorm(self.l1.config.hidden_size)\n",
    "        self.l2 = nn.Linear(self.l1.config.hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, ids, mask, token_type_ids):\n",
    "        outputs = self.l1(ids, attention_mask=mask, token_type_ids = token_type_ids)\n",
    "        last_hidden_state = outputs[0]  # Get the last hidden state\n",
    "        \n",
    "        # Pooling: Use the [CLS] token representation (first token)\n",
    "        pooled_output = last_hidden_state[:, 0, :]\n",
    "        \n",
    "        output_2 = self.dropout(pooled_output)\n",
    "        output_3 = self.layer_norm(output_2)\n",
    "        output = self.l2(output_3)\n",
    "        return output    \n",
    "    \n",
    "model = DEBERTAClass(13) # Change for number of classes estimating\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de82c9f0-a61f-45ae-bc03-6cd3475e585a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function\n",
    "def loss_fn(outputs, targets):\n",
    "    return torch.nn.BCEWithLogitsLoss()(outputs, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf0eb36-41c1-41df-9186-a4bab82d63cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "optimizer = torch.optim.Adam(params = model.parameters(), lr = LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02aa3735-4e7d-4446-a17e-00e012f68dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defined training function\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    for batch in tqdm.tqdm(training_loader, desc = f\"Epoch {epoch}\"):\n",
    "        # Unpack the batch\n",
    "        ids = batch['ids'].to(device, dtype = torch.long)\n",
    "        mask = batch['mask'].to(device, dtype = torch.long)\n",
    "        token_type_ids = batch['token_type_ids'].to(device, dtype = torch.long)\n",
    "        targets = batch['targets'].to(device, dtype = torch.float)\n",
    "        \n",
    "        outputs = model(ids, mask, token_type_ids)\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'Epoch: {epoch}, Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b850352-2242-44be-982b-c9c0d6eaf655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Function\n",
    "for epoch in range(EPOCHS):\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe4130f-a6fc-412d-8688-4c9584723eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation Function\n",
    "def validation(epoch):\n",
    "    model.eval()\n",
    "    fin_targets = []\n",
    "    fin_outputs = []\n",
    "    texts = []\n",
    "    caseid = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm.tqdm(testing_loader, desc = f\"Validation Epoch {epoch}\"):\n",
    "            ids = batch['ids'].to(device, dtype = torch.long)\n",
    "            mask = batch['mask'].to(device, dtype = torch.long)\n",
    "            token_type_ids = batch['token_type_ids'].to(device, dtype = torch.long)\n",
    "            targets = batch['targets'].to(device, dtype = torch.float)\n",
    "            \n",
    "            outputs = model(ids, mask, token_type_ids)\n",
    "            \n",
    "            fin_targets.extend(targets.cpu().detach().numpy().tolist())\n",
    "            fin_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n",
    "            texts.extend(batch['text'])  # Extracting the text column\n",
    "            caseid.extend(batch['caseid'])\n",
    "    \n",
    "    return fin_outputs, fin_targets, texts, caseid\n",
    "\n",
    "# For Test Data\n",
    "for epoch in range(1):\n",
    "    outputs, targets, texts, caseid = validation(epoch)\n",
    "    outputs = np.array(outputs) >= 0.65                                      #This can be tuned\n",
    "    accuracy = metrics.accuracy_score(targets, outputs)\n",
    "    f1_score_micro = metrics.f1_score(targets, outputs, average = 'micro')\n",
    "    f1_score_macro = metrics.f1_score(targets, outputs, average = 'macro')\n",
    "    print(f\"Accuracy Score = {accuracy}\")\n",
    "    print(f\"F1 Score (Micro) = {f1_score_micro}\")\n",
    "    print(f\"F1 Score (Macro) = {f1_score_macro}\")\n",
    "    #print(\"First three items of texts:\", texts[:3])\n",
    "    #print(\"First three items of fin_outputs:\", outputs[:3])\n",
    "    #print(\"First three items of fin_targets:\", targets[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee91c83-2179-47a0-9df4-b7a019407e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation Function\n",
    "def validation(epoch):\n",
    "    model.eval()\n",
    "    fin_targets = []\n",
    "    fin_outputs = []\n",
    "    texts = []\n",
    "    caseid = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm.tqdm(validation_loader, desc = f\"Validation Epoch {epoch}\"):\n",
    "            ids = batch['ids'].to(device, dtype = torch.long)\n",
    "            mask = batch['mask'].to(device, dtype = torch.long)\n",
    "            token_type_ids = batch['token_type_ids'].to(device, dtype = torch.long)\n",
    "            targets = batch['targets'].to(device, dtype = torch.float)\n",
    "            \n",
    "            outputs = model(ids, mask, token_type_ids)\n",
    "            \n",
    "            fin_targets.extend(targets.cpu().detach().numpy().tolist())\n",
    "            fin_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n",
    "            texts.extend(batch['text'])  # Extracting the text column\n",
    "            caseid.extend(batch['caseid'])\n",
    "    \n",
    "    return fin_outputs, fin_targets, texts, caseid\n",
    "\n",
    "# For Validation (Hold out) Data\n",
    "for epoch in range(1):\n",
    "    outputs, targets, texts, caseid = validation(epoch)\n",
    "    outputs = np.array(outputs) >= 0.65                                      \n",
    "    accuracy = metrics.accuracy_score(targets, outputs)\n",
    "    f1_score_micro = metrics.f1_score(targets, outputs, average = 'micro')\n",
    "    f1_score_macro = metrics.f1_score(targets, outputs, average = 'macro')\n",
    "    print(f\"Accuracy Score = {accuracy}\")\n",
    "    print(f\"F1 Score (Micro) = {f1_score_micro}\")\n",
    "    print(f\"F1 Score (Macro) = {f1_score_macro}\")\n",
    "    #print(\"First three items of texts:\", texts[:3])\n",
    "    #print(\"First three items of fin_outputs:\", outputs[:3])\n",
    "    #print(\"First three items of fin_targets:\", targets[:3])\n",
    "    \n",
    "    # Create a dictionary with column names as keys and lists as values\n",
    "    final_df = {\n",
    "        'Outputs': outputs,\n",
    "        'Targets': targets,\n",
    "        'Texts': texts,\n",
    "        'Caseid': caseid\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716703af-b96c-49bd-b540-5a1387098f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating final output\n",
    "final_case = final_df['Caseid']\n",
    "final_case = pd.DataFrame(final_case, columns = [\"Caseid\"])\n",
    "\n",
    "final_text = final_df['Texts']\n",
    "final_text = pd.DataFrame(final_text, columns = [\"Text\"])\n",
    "\n",
    "final_output = final_df['Outputs']\n",
    "final_output = pd.DataFrame(final_output, columns = [\"Freedom and Rights\", \"E Plurabus Unum\", \"Representation of the People\", \"Popular Will and Equality\", \"National Identity and Heritage\", \"Not a Democracy a Republic\", \n",
    "                \"Flawed Democracy\", \"Institution and Constitution\", \"Unclassified/Other\", \"Don't Know\", \"Nothing/Disaffected\", \"Nothing More to Add\", \"NA\"])\n",
    "final_output.replace({True: 1, False: 0}, inplace = True)\n",
    "\n",
    "final_df = final_text.join(final_output)\n",
    "final_df = final_case.join(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cedb6ac3-8a6c-4282-82aa-9d0d95cca77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e995014-7073-48c7-a7c2-d3efd5187100",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "\n",
    "true_np = targets\n",
    "pred_np = outputs\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = multilabel_confusion_matrix(true_np, pred_np)\n",
    "\n",
    "# Define label titles\n",
    "label_titles = [\"Freedom and Rights\", \"E Plurabus Unum\", \"Representation of the People\", \"Popular Will and Equality\", \"National Identity and Heritage\", \"Not a Democracy a Republic\", \n",
    "                \"Flawed Democracy\", \"Institution and Constitution\", \"Unclassified/Other\", \"Don't Know\", \"Nothing/Disaffected\", \"Nothing More to Add\", \"NA\"]\n",
    "\n",
    "# Create a dictionary to store confusion matrices with titles\n",
    "conf_matrix_dict = {}\n",
    "for i, title in enumerate(label_titles):\n",
    "    conf_matrix_dict[title] = conf_matrix[i]\n",
    "\n",
    "# Print confusion matrices with titles\n",
    "for title, matrix in conf_matrix_dict.items():\n",
    "    print(f\"Confusion matrix for {title}:\")\n",
    "    print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e406fee1-4ec9-4a04-a01c-95a76267495c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model, \"/storage/home/ndh5286/Projects/MOTN Transformer/NLI_DeBERTaV2_transformer_7.18.24.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edb64da-df10-423e-b13d-e4eec07e2b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = torch.load(\"/storage/home/ndh5286/Projects/MOTN Transformer/final_model_6.2.24.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
